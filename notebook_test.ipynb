{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from activation_function import Tanh, Linear, ReLU, Sigmoid\n",
    "from layer import Layer\n",
    "from mlp import MLP\n",
    "from metrics import Metrics\n",
    "from losses import MeanSquaredError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solve XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
    "oracle = [[0], [1], [1], [0]]\n",
    "\n",
    "mlp = MLP()\n",
    "metrics = Metrics()\n",
    "act_func1 = ReLU()\n",
    "act_func2 = Sigmoid()\n",
    "lr = 0.1\n",
    "\n",
    "mlp.add(Layer(5, act_func=act_func1, n_inputs=len(input[0])))\n",
    "mlp.add(Layer(len(oracle[0]), act_func=act_func2, n_inputs=5))\n",
    "\n",
    "mlp.compile(lr, MeanSquaredError())\n",
    "\n",
    "mlp.fit(input, oracle, epochs=2000)\n",
    "\n",
    "for i in range(len(input)):\n",
    "    out = mlp.run(input[i])\n",
    "    print(f'case {i}: {np.round(out), oracle[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOLVE IRIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('archive/Iris.csv')\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Species'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data[\"Species\"]==\"Iris-setosa\",\"Species\"]      =   0.1\n",
    "data.loc[data[\"Species\"]==\"Iris-versicolor\",\"Species\"]  =   0.5\n",
    "data.loc[data[\"Species\"]==\"Iris-virginica\",\"Species\"]   =   0.9\n",
    "\n",
    "#data.drop(data[data['Species'] == 2].index, inplace=True)\n",
    "\n",
    "data=data.iloc[np.random.permutation(len(data))]\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_splits\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "df_scaled = scaler.fit_transform(data.to_numpy())\n",
    "df_scaled = pd.DataFrame(df_scaled, columns=data.columns.values)\n",
    "del df_scaled['Species']\n",
    "del df_scaled['Id']\n",
    "df_scaled = df_scaled.assign(Species=data['Species'].values)\n",
    "\n",
    "df_train, df_test, _ = get_splits(df_scaled, 0.8, 0.2)\n",
    "print(df_train ,len(df_train))\n",
    "print(df_test, len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseOracle(values):\n",
    "    out=[]\n",
    "    for i in range(len(values)):\n",
    "        if values[i] == 0:\n",
    "            out.append(np.array([1,0,0]))\n",
    "        elif values[i] == 1:\n",
    "            out.append(np.array([1,1,0]))\n",
    "        else:\n",
    "            out.append(np.array([1,1,1]))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.iloc[ : , :4].values\n",
    "y_train = df_train.iloc[:,4:].values\n",
    "print(X_train[:3], y_train[3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [\n",
    "    Layer(\n",
    "        n_perceptrons=len(X_train[0]),\n",
    "        n_inputs=len(X_train[0]),\n",
    "        act_func=ReLU(),\n",
    "        #kernel_regularizer=0.02,\n",
    "        #bias_regularizer=0.01,\n",
    "        momentum=0.5\n",
    "    ),\n",
    "    Layer(\n",
    "        n_perceptrons=len(y_train[0]),\n",
    "        n_inputs=len(X_train[0]),\n",
    "        act_func=Sigmoid(),\n",
    "        #kernel_regularizer=0.02,\n",
    "        #bias_regularizer=0.01,\n",
    "        momentum=0.5\n",
    "    )\n",
    "]\n",
    "\n",
    "model = MLP(layers)\n",
    "\n",
    "epochs, lr = 1000, 0.1\n",
    "loss = MeanSquaredError()\n",
    "\n",
    "model.compile(lr,loss)\n",
    "model.fit(X_train, y_train, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test.iloc[ : , :4].values\n",
    "y_test = df_test.iloc[:,4:].values\n",
    "\n",
    "def parse(out):\n",
    "    if out > 0.75:\n",
    "        return 0.9\n",
    "    elif out < 0.25:\n",
    "        return 0.1\n",
    "    else:\n",
    "        return 0.5\n",
    "error = 0  \n",
    "for i in range(len(X_test)):\n",
    "    out = model.run(X_test[i])\n",
    "    print(f'case {i}: {parse(out)}, {y_test[i][0]}')\n",
    "    if parse(out) != y_test[i][0]:\n",
    "        error += 1\n",
    "print(\"error: \", error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
