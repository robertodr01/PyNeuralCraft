{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from activation_function import Tanh, Linear, ReLU, Sigmoid\n",
    "from layer import Layer\n",
    "from mlp import MLP\n",
    "from metrics import Metrics\n",
    "from losses import MeanSquaredError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solve XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
    "oracle = [[0], [1], [1], [0]]\n",
    "\n",
    "mlp = MLP()\n",
    "metrics = Metrics()\n",
    "act_func1 = ReLU()\n",
    "act_func2 = Sigmoid()\n",
    "lr = 0.1\n",
    "\n",
    "mlp.add(Layer(5, act_func=act_func1, n_inputs=len(input[0])))\n",
    "mlp.add(Layer(len(oracle[0]), act_func=act_func2, n_inputs=5))\n",
    "\n",
    "mlp.compile(lr, MeanSquaredError())\n",
    "\n",
    "mlp.fit(input, oracle, epochs=2000)\n",
    "\n",
    "for i in range(len(input)):\n",
    "    out = mlp.run(input[i])\n",
    "    print(f'case {i}: {np.round(out), oracle[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOLVE IRIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('archive/Iris.csv')\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Species'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data[\"Species\"]==\"Iris-setosa\",\"Species\"]      =   0.1\n",
    "data.loc[data[\"Species\"]==\"Iris-versicolor\",\"Species\"]  =   0.5\n",
    "data.loc[data[\"Species\"]==\"Iris-virginica\",\"Species\"]   =   0.9\n",
    "\n",
    "#data.drop(data[data['Species'] == 2].index, inplace=True)\n",
    "\n",
    "data=data.iloc[np.random.permutation(len(data))]\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_splits\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "df_scaled = scaler.fit_transform(data.to_numpy())\n",
    "df_scaled = pd.DataFrame(df_scaled, columns=data.columns.values)\n",
    "del df_scaled['Species']\n",
    "del df_scaled['Id']\n",
    "df_scaled = df_scaled.assign(Species=data['Species'].values)\n",
    "\n",
    "df_train, df_test, _ = get_splits(df_scaled, 0.8, 0.2)\n",
    "print(df_train ,len(df_train))\n",
    "print(df_test, len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseOracle(values):\n",
    "    out=[]\n",
    "    for i in range(len(values)):\n",
    "        if values[i] == 0:\n",
    "            out.append(np.array([1,0,0]))\n",
    "        elif values[i] == 1:\n",
    "            out.append(np.array([1,1,0]))\n",
    "        else:\n",
    "            out.append(np.array([1,1,1]))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.iloc[ : , :4].values\n",
    "y_train = df_train.iloc[:,4:].values\n",
    "print(X_train[:3], y_train[3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [\n",
    "    Layer(\n",
    "        n_perceptrons=len(X_train[0]),\n",
    "        n_inputs=len(X_train[0]),\n",
    "        act_func=ReLU(),\n",
    "        #kernel_regularizer=0.02,\n",
    "        #bias_regularizer=0.01,\n",
    "        momentum=0.5\n",
    "    ),\n",
    "    Layer(\n",
    "        n_perceptrons=len(y_train[0]),\n",
    "        n_inputs=len(X_train[0]),\n",
    "        act_func=Sigmoid(),\n",
    "        #kernel_regularizer=0.02,\n",
    "        #bias_regularizer=0.01,\n",
    "        momentum=0.5\n",
    "    )\n",
    "]\n",
    "\n",
    "model = MLP(layers)\n",
    "\n",
    "epochs, lr = 1000, 0.1\n",
    "loss = MeanSquaredError()\n",
    "\n",
    "model.compile(lr,loss)\n",
    "model.fit(X_train, y_train, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test.iloc[ : , :4].values\n",
    "y_test = df_test.iloc[:,4:].values\n",
    "\n",
    "def parse(out):\n",
    "    if out > 0.75:\n",
    "        return 0.9\n",
    "    elif out < 0.25:\n",
    "        return 0.1\n",
    "    else:\n",
    "        return 0.5\n",
    "error = 0  \n",
    "for i in range(len(X_test)):\n",
    "    out = model.run(X_test[i])\n",
    "    print(f'case {i}: {parse(out)}, {y_test[i][0]}')\n",
    "    if parse(out) != y_test[i][0]:\n",
    "        error -= 1\n",
    "print(\"error: \", error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlp import MLP\n",
    "from layer import Layer\n",
    "from activation_function import instantiate_act_func\n",
    "from weigth_init import instantiate_initializer\n",
    "from losses import instantiate_loss\n",
    "import numpy as np\n",
    "\n",
    "def create_model_from_test(test):\n",
    "    layers = []\n",
    "    n_processes = None\n",
    "    for layer in test['layers']:\n",
    "        layers.append(\n",
    "            Layer(\n",
    "                layer['units'],\n",
    "                instantiate_act_func(layer['act_func']),\n",
    "                layer['inputs'],\n",
    "                weights_initializer=instantiate_initializer(test['weights_initializer']),\n",
    "                kernel_regularizer=test['kernel_regularizer'],\n",
    "                bias_regularizer=test['bias_regularizer'],\n",
    "                momentum=test['momentum'],\n",
    "                Nesterov=test['Nesterov'],\n",
    "                n_processes=n_processes\n",
    "            )\n",
    "        )\n",
    "    mlp = MLP(layers)\n",
    "    mlp.compile(test['learning_rate'],instantiate_loss(test['loss']), test['metrics'])\n",
    "    return mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ML (loss=10934618.81): 100%|██████████| 50/50 [00:00<00:00, 775.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4290.54024038] 60\n",
      "[-4193.19265493] 60\n",
      "[-3746.1835115] 60\n",
      "[-2617.74126993] 40\n",
      "[-2170.7321265] 40\n",
      "[298.73754537] 40\n",
      "[590.78030171] 40\n",
      "[-1976.0369556] 40\n",
      "[-984.67108329] 40\n",
      "[-5476.60128359] 60\n",
      "[-5029.59214015] 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X = [\n",
    "    [-6, -3],\n",
    "    [-6, -2],\n",
    "    [-5, -4],\n",
    "    [-4,  1],\n",
    "    [-3, -1],\n",
    "    [ 1, -2],\n",
    "    [ 1,  1],\n",
    "    [-3,  1],\n",
    "    [-1, -2],\n",
    "    [-8, -2],\n",
    "    [-7, -4],\n",
    "]\n",
    "y = [\n",
    "    60,\n",
    "    60,\n",
    "    60,\n",
    "    40,\n",
    "    40,\n",
    "    40,\n",
    "    40,\n",
    "    40,\n",
    "    40,\n",
    "    60,\n",
    "    60,\n",
    "]\n",
    "\n",
    "test = {'learning_rate': 0.02, 'momentum': 0.9, 'Nesterov': True, 'kernel_regularizer': 0, 'bias_regularizer': 0, 'weights_initializer': 'random_init', 'layers': [{'units': 1, 'inputs': 2, 'act_func': 'linear'}], 'name': 'model3', 'epochs': 250, 'loss': 'mean_squared_error', 'metrics': ['accuracy']}\n",
    "model = create_model_from_test(test)\n",
    "model.fit(X, y, epochs=50)\n",
    "for i, j in zip(X, y):\n",
    "    out = model.run(i)\n",
    "    print(out, j)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
