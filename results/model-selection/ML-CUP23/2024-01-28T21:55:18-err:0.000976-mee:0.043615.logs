{'learning_rate': 0.09, 'momentum': 0.9, 'Nesterov': True, 'kernel_regularizer': 0, 'bias_regularizer': 0, 'weights_initializer': 'xavier_uniform_init', 'layers': [{'units': 10, 'inputs': 10, 'act_func': 'sigmoid'}, {'units': 10, 'inputs': 10, 'act_func': 'sigmoid'}, {'units': 3, 'inputs': 10, 'act_func': 'sigmoid'}], 'name': 'model3', 'epochs': 500, 'loss': 'mean_squared_error', 'metrics': ['mean_euclidean_error']}
--------------- Layer ---------------
--------------- Perceptron ---------------
---------------  Weights   ---------------
[-0.51634248 -0.10828085 -0.87152138  0.2460946   1.00487239  0.29150415
 -0.86961892  0.43962853 -1.25074897  0.74239475]
---------------    Bias    ---------------
[-0.43835]

--------------- Perceptron ---------------
---------------  Weights   ---------------
[-0.0862172  -1.07264183 -0.67843973 -0.67049887  1.20935446  0.54982268
  0.66078767 -0.9585877   0.25058509  0.00325596]
---------------    Bias    ---------------
[0.58792667]

--------------- Perceptron ---------------
---------------  Weights   ---------------
[ 0.83552014 -0.52983934  1.3791747  -0.56856555  0.23733899  0.31467624
  0.14622683  0.15005597 -0.71395317 -0.07339724]
---------------    Bias    ---------------
[-0.124396]

--------------- Perceptron ---------------
---------------  Weights   ---------------
[-0.7893639   0.30959366  0.08740086  0.26208877 -1.13567178 -0.42601578
 -0.23198413 -1.01324005  0.62868346  0.66535769]
---------------    Bias    ---------------
[-0.25057628]

--------------- Perceptron ---------------
---------------  Weights   ---------------
[ 0.59934993 -0.62488242  0.14420413  0.61513414  0.56832732  1.52308028
 -0.57526303  0.50207718  0.32300917 -0.51513383]
---------------    Bias    ---------------
[-0.63965945]

--------------- Perceptron ---------------
---------------  Weights   ---------------
[ 0.28297394  0.53806271  0.4517267  -0.19121996 -0.00798102 -0.26159962
  1.07870873 -0.0115072   0.0500042  -0.85174126]
---------------    Bias    ---------------
[1.13318064]

--------------- Perceptron ---------------
---------------  Weights   ---------------
[ 0.76760701 -0.44155317  0.93161515 -0.38259847  0.28669927  0.50868859
  0.16470239 -0.67498763  0.23303062  0.54304203]
---------------    Bias    ---------------
[-0.58846743]

--------------- Perceptron ---------------
---------------  Weights   ---------------
[-0.07813211  0.61342845 -0.1266169  -0.10502408  0.25317765 -0.52535032
 -0.76730098  0.53591822 -0.66538281  0.73181573]
---------------    Bias    ---------------
[-0.82490218]

--------------- Perceptron ---------------
---------------  Weights   ---------------
[ 0.82371067  0.07675526  0.40445594 -0.0080724  -0.85196805 -1.14591188
  0.51268511  0.4781646  -0.20638782 -0.98834172]
---------------    Bias    ---------------
[-0.288826]

--------------- Perceptron ---------------
---------------  Weights   ---------------
[-0.71151333  0.1468048  -0.12118705 -0.53923538 -0.38012013  0.67168183
  0.68243747 -0.67057098  0.33133921  1.78007863]
---------------    Bias    ---------------
[-0.15429732]


--------------- Layer ---------------
--------------- Perceptron ---------------
---------------  Weights   ---------------
[-0.96004331 -1.74869524  1.1038653  -0.75870597  1.67007479 -0.54582728
  0.14198229  0.31418013  0.45918655 -1.20967022]
---------------    Bias    ---------------
[-0.31524302]

--------------- Perceptron ---------------
---------------  Weights   ---------------
[ 1.44123258 -1.14054682 -0.25656902 -0.33671491  1.29602763 -0.16227827
 -0.50115053  1.05309108 -0.87667208 -1.10879366]
---------------    Bias    ---------------
[0.02381154]

--------------- Perceptron ---------------
---------------  Weights   ---------------
[ 0.69504568 -0.17899706 -0.55753586 -0.56571144  0.0517579  -0.03372148
 -0.13002612  0.45376099 -0.65923497 -0.72056215]
---------------    Bias    ---------------
[-0.1988436]

--------------- Perceptron ---------------
---------------  Weights   ---------------
[-0.45239346  0.02415483  1.16879686 -0.31125563  0.24870125  1.28012295
  0.21434612 -0.4238962   1.47946004  0.60781343]
---------------    Bias    ---------------
[0.77331919]

--------------- Perceptron ---------------
---------------  Weights   ---------------
[ 0.70637605  0.36742644  0.55953925 -0.82296816  0.33195194 -1.48712904
  1.21180419  0.02812427 -1.76768559 -0.32193054]
---------------    Bias    ---------------
[-0.3606632]

--------------- Perceptron ---------------
---------------  Weights   ---------------
[ 0.32283319 -0.56716235 -1.43601569  1.41134191  0.2088933  -0.73068937
 -1.58724975  1.22721533 -0.34527942 -0.68667432]
---------------    Bias    ---------------
[0.02493568]

--------------- Perceptron ---------------
---------------  Weights   ---------------
[-0.37890354  0.70904432 -0.79463706  1.50083883 -1.44447864  1.05478019
 -0.68493588  0.77001402  1.33889823  0.19662974]
---------------    Bias    ---------------
[0.61514433]

--------------- Perceptron ---------------
---------------  Weights   ---------------
[ 0.49344712  0.84643318 -0.23464858  0.45569794  0.03224748 -0.25767767
  0.71294399 -0.36088103 -0.68588466  0.73580043]
---------------    Bias    ---------------
[-0.17144092]

--------------- Perceptron ---------------
---------------  Weights   ---------------
[ 0.10369408  1.56392709 -0.12520064  0.48057128 -1.42101432  0.15544155
  0.30491585 -0.05442826  0.22999863  1.13860661]
---------------    Bias    ---------------
[0.08461663]

--------------- Perceptron ---------------
---------------  Weights   ---------------
[-0.934957    0.36550834  0.67134813  1.09047207 -0.91035902  1.31828392
 -0.82650596 -0.26225106  1.49537268  0.47269186]
---------------    Bias    ---------------
[0.6720517]


--------------- Layer ---------------
--------------- Perceptron ---------------
---------------  Weights   ---------------
[-1.75383863 -0.76740786 -0.11997156 -1.45060762  1.69986191  1.73130802
  0.64861229  0.87323288  0.99324377 -0.70919319]
---------------    Bias    ---------------
[0.66654055]

--------------- Perceptron ---------------
---------------  Weights   ---------------
[ 0.6620269   1.23652714 -0.05565948 -0.55147016 -1.96491536  2.64398578
  1.65485948 -0.56123051 -0.74042224  0.48614682]
---------------    Bias    ---------------
[-0.65475592]

--------------- Perceptron ---------------
---------------  Weights   ---------------
[ 2.13720451  2.87273327  1.1496117  -0.49912074  2.77767412  0.6284066
 -2.39529948  0.1447973  -1.25383944 -1.87255218]
---------------    Bias    ---------------
[0.56771039]



