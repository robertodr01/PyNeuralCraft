{'learning_rate': 0.8, 'momentum': 0.9, 'Nesterov': True, 'kernel_regularizer': 0.0001, 'bias_regularizer': 0, 'weights_initializer': 'xavier_uniform_init', 'layers': [{'units': 15, 'inputs': 10, 'act_func': 'sigmoid'}, {'units': 15, 'inputs': 15, 'act_func': 'sigmoid'}, {'units': 3, 'inputs': 15, 'act_func': 'sigmoid'}], 'name': 'model2', 'epochs': 500, 'loss': 'mean_squared_error', 'metrics': ['mean_euclidean_error']}
mse_train:29.184417-mee_train:7.915435
mse_val:43.693239-mee_val:10.105892
--------------- Layer ---------------
--------------- Perceptron ---------------
---------------  Weights   ---------------
[ 0.11421809  0.84791427  0.0370191   0.22242833 -0.49527118 -0.61940083
 -0.27382978  0.44205718  0.03844234 -0.45600968]
---------------    Bias    ---------------
[1.49906173]

--------------- Perceptron ---------------
---------------  Weights   ---------------
[-0.35052554  0.32278173 -0.28974049  0.11783036  0.1048082  -0.17145171
 -0.40073612  0.18525254 -0.09403244  0.23992124]
---------------    Bias    ---------------
[-1.04236297]

--------------- Perceptron ---------------
---------------  Weights   ---------------
[-0.6514406   0.43223922 -0.32873013  0.04060962 -0.0487898  -0.34657825
  0.00950617 -0.21002095  0.4883921   0.50672468]
---------------    Bias    ---------------
[0.51369508]

--------------- Perceptron ---------------
---------------  Weights   ---------------
[-0.5177887   0.51956198 -0.40683196  0.15890312  0.05440513 -0.37558249
 -0.27556445  0.0161427   0.23382448  0.49528089]
---------------    Bias    ---------------
[-0.21115614]

--------------- Perceptron ---------------
---------------  Weights   ---------------
[-0.1172275  -0.14536659 -0.25450846  0.0590978   0.21032614  0.12277116
 -0.50660206  0.1643463  -0.38358848  0.26640952]
---------------    Bias    ---------------
[-1.24317065]

--------------- Perceptron ---------------
---------------  Weights   ---------------
[-0.15244225 -0.77465658 -0.06009964 -0.17908681  0.48290685  0.54495261
  0.16383025 -0.44036116 -0.16066238  0.48578438]
---------------    Bias    ---------------
[0.01745272]

--------------- Perceptron ---------------
---------------  Weights   ---------------
[-0.67643907 -0.25975123 -0.33303173 -0.01193184  0.28619977  0.24324469
 -0.12591398 -0.45615278 -0.03936227  0.98326941]
---------------    Bias    ---------------
[0.89896657]

--------------- Perceptron ---------------
---------------  Weights   ---------------
[ 0.51372486 -0.71541995 -0.00390096  0.17544162  0.47339106  0.39213221
 -0.39256942 -0.21356399 -0.45867673  0.52355227]
---------------    Bias    ---------------
[-1.31142015]

--------------- Perceptron ---------------
---------------  Weights   ---------------
[-0.16476484  0.04128065 -0.18064266  0.25115769  0.33179107  0.33870641
 -0.74315162  0.45228006 -0.59920887 -0.05766159]
---------------    Bias    ---------------
[-1.46591377]

--------------- Perceptron ---------------
---------------  Weights   ---------------
[ 0.00731666  0.0007206   0.00307413  0.00066218 -0.00238371  0.00080653
 -0.00593666  0.00586321 -0.00547539 -0.00629125]
---------------    Bias    ---------------
[4.59544187]

--------------- Perceptron ---------------
---------------  Weights   ---------------
[-0.51484984  0.16843865 -0.07747641 -0.20487815 -0.16743601 -0.45694054
  0.75942707 -0.45399846  0.570564    0.37460968]
---------------    Bias    ---------------
[1.80759771]

--------------- Perceptron ---------------
---------------  Weights   ---------------
[-0.26470696  0.23605273 -0.20203211  0.15792475  0.20670954  0.15430008
 -0.60288895  0.42864812 -0.43632126 -0.09323116]
---------------    Bias    ---------------
[-1.53595109]

--------------- Perceptron ---------------
---------------  Weights   ---------------
[ 0.00714485  0.00070624  0.00300148  0.00065025 -0.00232601  0.00078899
 -0.00579812  0.00572811 -0.00534843 -0.00614454]
---------------    Bias    ---------------
[4.61955557]

--------------- Perceptron ---------------
---------------  Weights   ---------------
[ 0.00821425  0.00079296  0.00345428  0.00072153 -0.0026862   0.00089758
 -0.00665943  0.00656657 -0.0061374  -0.00705677]
---------------    Bias    ---------------
[4.47809768]

--------------- Perceptron ---------------
---------------  Weights   ---------------
[ 0.08939348 -0.08161658 -0.0434929   0.36859     0.4400788   0.57443877
 -0.89409739  0.44392056 -0.66317638 -0.13657445]
---------------    Bias    ---------------
[-1.2187766]


--------------- Layer ---------------
--------------- Perceptron ---------------
---------------  Weights   ---------------
[-8.76972284e-05  1.08887769e-05  7.87901968e-06  1.30437870e-05
  2.86575588e-05  2.60450732e-05  4.97112279e-05  2.97513624e-05
  1.41822734e-05 -6.13504178e-05 -2.56714136e-05  6.18935764e-06
 -6.13637512e-05 -6.12813201e-05  2.67925847e-06]
---------------    Bias    ---------------
[-2.67167219]

--------------- Perceptron ---------------
---------------  Weights   ---------------
[-0.00156258  0.00300262  0.00592856  0.00472213  0.00481512  0.00931245
  0.01171888  0.0058923   0.00240044  0.00544022  0.00671034  0.00144792
  0.00544163  0.00543277  0.00192077]
---------------    Bias    ---------------
[3.38893997]

--------------- Perceptron ---------------
---------------  Weights   ---------------
[-5.81157974e-05  4.43676285e-06  5.01984629e-06  8.99596505e-06
 -1.65436045e-06 -1.99199845e-05  4.44476991e-06  1.07377490e-05
  1.15338704e-05 -6.84808998e-05 -2.53207765e-05  8.78248260e-06
 -6.84960624e-05 -6.84022338e-05  6.27338730e-06]
---------------    Bias    ---------------
[-2.9204061]

--------------- Perceptron ---------------
---------------  Weights   ---------------
[-0.16531638  0.37120571 -0.23829154  0.07510115  0.86674746  0.32298416
  0.66701427  1.0182968   1.22434309  0.0285813  -0.69214926  0.83611953
  0.02857064  0.02864261  1.41335073]
---------------    Bias    ---------------
[-2.3072906]

--------------- Perceptron ---------------
---------------  Weights   ---------------
[-0.00429112 -0.00073665 -0.00266725 -0.0020116   0.00151259  0.00171271
  0.00059785  0.00341959  0.00195576 -0.00253305 -0.00374552  0.00060776
 -0.00253368 -0.00252976  0.00246795]
---------------    Bias    ---------------
[-1.20518995]

--------------- Perceptron ---------------
---------------  Weights   ---------------
[-0.00171138  0.00306967  0.00606348  0.00483133  0.00493762  0.00954408
  0.01202385  0.00604444  0.00244682  0.00547807  0.00683257  0.00146963
  0.00547951  0.00547055  0.00194006]
---------------    Bias    ---------------
[3.35732162]

--------------- Perceptron ---------------
---------------  Weights   ---------------
[ 0.44309607  0.88225132  1.20416929  1.29456938  0.40787336 -0.19681275
  0.84247493 -0.45050111  0.24899092 -0.01828498  0.58074147  0.45637071
 -0.01826664 -0.01838947 -0.05559333]
---------------    Bias    ---------------
[-3.04696828]

--------------- Perceptron ---------------
---------------  Weights   ---------------
[-3.63039933e-04  4.27040971e-05  3.12790535e-05  5.07561561e-05
  1.19693010e-04  1.17956160e-04  2.10794221e-04  1.30732277e-04
  5.89294106e-05 -2.45359373e-04 -1.01600567e-04  2.40803060e-05
 -2.45412583e-04 -2.45083667e-04  1.31594390e-05]
---------------    Bias    ---------------
[-2.14680237]

--------------- Perceptron ---------------
---------------  Weights   ---------------
[-0.00342451 -0.00020448 -0.00104372 -0.00071972  0.00110029  0.00132603
  0.00115919  0.00205631  0.00100628 -0.0020743  -0.0019735   0.00028193
 -0.00207478 -0.00207178  0.00103997]
---------------    Bias    ---------------
[-1.30896997]

--------------- Perceptron ---------------
---------------  Weights   ---------------
[-0.00407985 -0.00056203 -0.00213707 -0.00158892  0.00139474  0.00161555
  0.00081844  0.00300345  0.00165121 -0.00242507 -0.00318397  0.0004995
 -0.00242566 -0.00242199  0.00200023]
---------------    Bias    ---------------
[-1.23024307]

--------------- Perceptron ---------------
---------------  Weights   ---------------
[-0.00158343  0.00301231  0.00594804  0.00473789  0.00483272  0.00934574
  0.01176267  0.00591413  0.00240717  0.00544613  0.00672814  0.00145111
  0.00544755  0.00543867  0.00192367]
---------------    Bias    ---------------
[3.38435928]

--------------- Perceptron ---------------
---------------  Weights   ---------------
[-0.00457147 -0.00103145 -0.00356019 -0.00272443  0.0016955   0.00184852
  0.00018971  0.00409188  0.00246364 -0.00266889 -0.00467199  0.00079233
 -0.00266958 -0.00266531  0.00325847]
---------------    Bias    ---------------
[-1.1718965]

--------------- Perceptron ---------------
---------------  Weights   ---------------
[ 0.78734438  0.07018885 -0.62372083 -0.32680601  0.14988721 -0.71225478
 -0.85674955  0.00391367  0.93499492  0.08800264 -1.07248467  0.72577681
  0.08799122  0.08807393  1.25673018]
---------------    Bias    ---------------
[0.25574452]

--------------- Perceptron ---------------
---------------  Weights   ---------------
[-1.45938165 -0.27735958 -0.2830167  -0.43816632  0.48031098  1.47501235
  1.15133089  1.26680119  0.08397591 -0.01556534  0.09165684 -0.20041737
 -0.01556263 -0.01558182  0.15702222]
---------------    Bias    ---------------
[-0.28454952]

--------------- Perceptron ---------------
---------------  Weights   ---------------
[-0.00147389  0.00296026  0.00584347  0.00465331  0.00473856  0.00916758
  0.01152852  0.00579745  0.00237092  0.00541268  0.00663197  0.00143375
  0.00541409  0.00540528  0.00190766]
---------------    Bias    ---------------
[3.40901322]


--------------- Layer ---------------
--------------- Perceptron ---------------
---------------  Weights   ---------------
[ 2.24823854e-03  2.49011138e-02  1.78020483e-03  8.75068241e-01
  5.01455968e-03  2.50957839e-02  2.58982808e+00  3.70762366e-03
  6.94559927e-03  5.72738344e-03  2.49287463e-02  3.73970440e-03
 -1.78481170e+00  1.45850309e+00  2.47822570e-02]
---------------    Bias    ---------------
[-0.88064437]

--------------- Perceptron ---------------
---------------  Weights   ---------------
[-8.65010608e-04 -1.95682459e-02 -5.91103770e-04 -5.30833032e-02
 -8.41270290e-03 -1.95836124e-02  1.94305242e+00 -1.52258507e-03
 -6.18659501e-03 -7.76738162e-03 -1.95703070e-02 -9.41630121e-03
  1.13177148e+00 -2.62044085e+00 -1.95598355e-02]
---------------    Bias    ---------------
[0.55730566]

--------------- Perceptron ---------------
---------------  Weights   ---------------
[ 2.17634272e-03  1.53256531e-02  1.78133806e-03  3.19749915e+00
  1.39405617e-02  1.53993065e-02 -7.89208427e-02  3.52909819e-03
  1.02012560e-02  1.27994862e-02  1.53360981e-02  1.57777833e-02
  2.01255308e+00  9.10506023e-01  1.52807569e-02]
---------------    Bias    ---------------
[-2.86883005]



